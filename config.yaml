llm:
  provider: llama_cpp
  model_path: ./models/llama-2-7b-chat.ggmlv3.q4_0.bin
  context_length: 2048
  temperature: 0.7
  max_tokens: 512

embedding:
  model: "sentence-transformers/all-MiniLM-L6-v2"
  batch_size: 32

vector_store:
  type: chroma
  path: ./vectorstore/db
  persist: true

document_dirs:
  - ./data/sample/

internet_retrieval:
  enabled: false
  allowlist_domains:
    - "arxiv.org"
    - "ieeexplore.ieee.org"
    - "scholar.google.com"
  request_timeout: 10
  user_agent: "RAG-Research-Assistant/1.0"

audit_log:
  file: ./audit.log
  level: INFO

output:
  citation_format: "ieee"
  output_dir: ./outputs/
  latex_template: "ieeeetran"